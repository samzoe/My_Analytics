{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8d1bc4",
   "metadata": {},
   "source": [
    "#### Applying polynomial features\n",
    "This project seeks to compare the generalisation performance of two linear models (LinearRegression and Ridge) on the make friedman dataset from scikit-learn. Polynomial features would then be applied to the best performing model to see how best it can improve upon its performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c470a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing the make_friedman1 function from scikit-learn\n",
    "from sklearn.datasets import make_friedman1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9405ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataset\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 12000, n_features = 25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2909486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_F1, y_F1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112696f2",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca42cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score\n",
      "\n",
      "Training set: 0.75 \n",
      "Test set: 0.76\n"
     ]
    }
   ],
   "source": [
    "#Importing the Linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model fitting\n",
    "linreg = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "# model evaluation using r2 score\n",
    "#Training set\n",
    "r2_score = linreg.score(X_train,y_train)\n",
    "\n",
    "#Test set\n",
    "r2_score1 = linreg.score(X_test,y_test)\n",
    "\n",
    "print(\"R2 Score\\n\")\n",
    "print(\"Training set: {:.2f} \".format(r2_score))\n",
    "print(\"Test set: {:.2f}\".format(r2_score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c1fee",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "603d1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.75 \n",
      "Test set score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Importing the ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# model fitting but this time we are going to loop through a number of alpha \n",
    "# parameters to see which one gives the best performance.\n",
    "\n",
    "linrig = Ridge(alpha = 5).fit(X_train,y_train)\n",
    "\n",
    "# model evaluation \n",
    "#Training set\n",
    "scoree = linrig.score(X_train,y_train)\n",
    "\n",
    "#Test set\n",
    "scoree1 = linrig.score(X_test,y_test)\n",
    "\n",
    "print(\"Training set score: {:.2f} \".format(scoree))\n",
    "print(\"Test set score: {:.2f}\".format(scoree1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071a249",
   "metadata": {},
   "source": [
    "##### Both models seem to have similar generalization performance given the best hyper parameter selections. However, ridge will be used going forward due to it's ability to reduce model complexity given the alpha parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278062c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.97 \n",
      "Test setscore: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Applying polynomial features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "X_poly = poly.fit_transform(X_F1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y_F1, random_state = 0)\n",
    "    \n",
    "linridge = Ridge(alpha = 5).fit(X_train,y_train)\n",
    "\n",
    "# model evaluation\n",
    "#Training set\n",
    "score = linridge.score(X_train,y_train)\n",
    "\n",
    "#Test set\n",
    "score1 = linridge.score(X_test,y_test)\n",
    "    \n",
    "print(\"Training set score: {:.2f} \".format(score))\n",
    "print(\"Test setscore: {:.2f}\".format(score1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73622153",
   "metadata": {},
   "source": [
    "As we can see, adding polynomial features to the linear model increased the model's performance drastically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
